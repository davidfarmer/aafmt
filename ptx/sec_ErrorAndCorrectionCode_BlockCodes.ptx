<section xml:id="sec_ErrorAndCorrectionCode_BlockCodes">
  <title>Block Codes</title>
  <p>
    In the examples we've seen so far,
    all message words are the same size,
    and all codewords are the same size
    (but message words and code words could be of different sizes,
    as in <xref ref="example_ErrorAndCorrectionCode_bit3">Example</xref>).
    This is certainly not the only possibility.
    For instance,
    we could encode different message words with codewords of differing sizes.
    Alternatively,
    we could use some kind of scheme which doesn't break the message into words at all.
    Such coding schemes have extremely important practical uses.
    Nonetheless,
    we will focus on the simple case where message words all have equal size,
    and all codewords also have equal size.
    These are called
    <q>block codes</q>, because both the original and encoded message are divided into
    <q>blocks</q>
    (e.g. codewords) of fixed size,
    and encoding /decoding proceeds block by block.
    We shall see shortly that group theory can be used to design block codes with very nice properties.
  </p>
  <p>
    We begin with a formal definition of block code,
    which generalizes the examples discussed in the previous section.
    In the following, the notation
    <m>\mathbb{Z}^{m}_{2}</m> denotes the set of binary <m>m</m>-tuples.
  </p>
  <definition>
    <statement>
      <p>
        {BlockCode} a <m>(n, m)</m> <term>block code</term>
            <idx><h>Block code</h></idx>
        consists of a one-to-one <term>encoding function</term>
            <idx><h>Function</h><h>encoding</h></idx>
        <me>
          E:\mathbb{Z}^{m}_{2} \rightarrow \mathbb{Z}^{n}_{2}
        </me>
        and an onto <term>decoding function</term>
            <idx><h>Decoding function</h></idx>
        <me>
          D:\mathbb{Z}^{n}_{2} \rightarrow \mathbb{Z}^{m}_{2}
        </me>.
      </p>
      <p>
        The functions <m>E</m> and <m>D</m> satisfy
        <m>D \compose E (z)= z</m> for any <m>z \in \mathbb{Z}_2^m</m>
        (in other words,
        <m>D \compose E</m> is the identity function on the set <m>\mathbb{Z}_2^m</m>).
      </p>
      <p>
        We refer to the elements of the domain of <m>E</m> as
        <term>message words</term>,
        and elements of the range of <m>E</m> as <term>codewords</term>.
      </p>
    </statement>
  </definition>
  <remark>
    <p>
      In <xref ref="definition_ErrorAndCorrectionCode_BlockCode">Definition</xref>,
      the encoding function <m>E</m> for a block code is required to be one-to-one so that two different message words are never assigned to the same codeword
      (which would make decoding impossible).
      On the other hand,
      the decoding function <m>D</m> is required to be onto so that any encoded message can be decoded
      (although the decoded message may have errors).
    </p>
  </remark>
  <exercise xml:id="exercise_ErrorAndCorrectionCode_DEstuff">
    <statement>
      <ol type="a">
        <li>
          <p>
            Explain why the definition requires that
            <m>D \compose E</m> is the identity function on the domain of <m>E</m>. (In other words,
            what property of encoding and decoding does this guarantee?)
          </p>
        </li>
        <li>
          <p>
            Show that the condition <m>D \compose E = \var{id}</m> implies that <m>D</m> is onto
            (in other words,
            to prove that <m>D</m> is a decoding function it's enough to prove that <m>D \compose E = \var{id}</m>,
            and you don't have to prove onto-ness separately).
          </p>
        </li>
        <li>
          <p>
            Show that in <xref ref="example_ErrorAndCorrectionCode_bit3">Example</xref>,
            it is not true that <m>E \compose D</m> is the identity function on the domain of <m>D</m>.
          </p>
        </li>
        <li>
          <p>
            Suppose that <m>E</m> and <m>D</m> are encoding and decoding functions for an error-correcting code.
            Prove that <m>E \compose D</m> is <em>not</em>
            equal to the identity function on the domain of <m>D</m>.
          </p>
        </li>
        <li>
          <p>
            Prove that for an error-correcting code,
            <m>E</m> and <m>D</m> are not inverse of each other.
          </p>
        </li>
      </ol>
    </statement>
  </exercise>
  <exercise>
    <statement>
      <p>
        According to <xref ref="definition_ErrorAndCorrectionCode_BlockCode">Definition</xref>,
        is it possible to have a <m>(n,m)</m> block code where <m>n > m</m>?
        Is <m>m > n</m> possible?
        <em>Explain</em> your answer.
      </p>
    </statement>
  </exercise>
  <example xml:id="example_ErrorAndCorrectionCode_evenparity">
    <statement>
      <p>
        The even-parity coding system developed to detect single errors in ASCII characters is an <m>(8,7)</m>-block code.
        The encoding function
            <idx><h>Encoding function</h></idx>
        is
        <me>
          E(x_7, x_6, \ldots, x_1) = (x_8, x_7,  \ldots, x_1)
        </me>,
        where <m>x_8 = x_7 + x_6 + \cdots + x_1</m>
        (the addition here is in <m>\mathbb{Z}_2</m>).
      </p>
      <p>
        One possible decoding function takes the 8-bit codeword and removes the front bit:
        <me>
          D(x_8,x_7, x_6, \ldots, x_1) = (x_7,  \ldots, x_1)
        </me>.
      </p>
      <p>
        This is a natural choice of decoding function,
        but it's not the only posssibility,
        as you will explore in the following exercise.
        There are several other possible decoding functions as well.
      </p>
    </statement>
  </example>
  <exercise>
    <statement>
      <ol type="a">
        <li>
          <p>
            Show that the function <m>D(x)</m> given above is a decoding function (remember that based on <xref ref="exercise_ErrorAndCorrectionCode_DEstuff">Exercise</xref>(b) it's enough to prove that <m>D \compose E = \var{id}</m>).
          </p>
        </li>
        <li>
          <p>
            Prove that the following function is also a decoding function for the even parity code:
            <me>
              D(x_8,x_7, x_6, \ldots, x_1) = ( x_8 + x_6 + \cdots + x_1, x_6,  \ldots, x_1) \textrm{(addition in } \mathbb{Z}_2)
            </me>.
          </p>
        </li>
        <li>
          <p>
            Give two more possible decoding functions for the even parity code.
          </p>
        </li>
      </ol>
    </statement>
  </exercise>
  <exercise>
    <statement>
      <ol type="a">
        <li>
          <p>
            Consider an even-parity coding system in which codewords have <m>k</m> bits.
          </p>
        </li>
        <li>
          <p>
            Is the code a block code?
            If so, what are the parameters <m>n</m> and <m>m</m>?
          </p>
        </li>
        <li>
          <p>
            What is the encoding function?
          </p>
        </li>
        <li>
          <p>
            Give two possible decoding functions.
          </p>
        </li>
      </ol>
    </statement>
  </exercise>
  <p>
    In order to characterize error detection and correction properties of codes,
    we need to quantify the degree of
    <q>similarity</q>
    between code words,
    since two code words that are similar are liable to be mistaken for each other.
    This leads naturally to the idea of
    <q>distance</q>
    between code words, defined as follows.
  </p>
  <definition>
    <statement>
      <p>
        {weight} Let <m>{\bold x} = (x_1, \ldots,
        x_n)</m> and <m>{\bold y} = (y_1, \ldots,
        y_n)</m> be binary <m>n</m>-tuples.
        The <term>Hamming distance</term>
            <idx><h>Hamming distance</h></idx>
        or <term>distance</term>,
        <m>d({\bold x}, {\bold y})</m> between <m>{\bold x}</m> and
        <m>{\bold y}</m> is the number of bit positions where
        <m>{\bold x}</m> and <m>{\bold y}</m> differ.
        The distance between two codewords is the minimum number of transmission errors required to change one codeword into the other.
        The <term>minimum distance</term><idx><h>Code</h><h>minimum distance of</h></idx> for a code,
        <m>d_{\min}</m> is the minimum of all distances <m>d({\bold x}, {\bold y})</m>,
        where <m>{\bold x}</m> and
        <m>{\bold y}</m> are distinct codewords.
        The <term>weight</term>
            <idx><h>Weight of a codeword</h></idx>,
            <idx><h>Codeword</h><h>weight of</h></idx>
        <m>w({\bold x})</m> of a binary codeword
        <m>{\bold x}</m> is the number of 1's in <m>{\bold x}</m>.
        It follows that <m>w({\bold x}) = d({\bold x}, {\bold 0})</m>,
        where <m>{\bold 0} = (00 \cdots 0)</m>,
        since <m>{\bold x}</m> differs from
        <m>{\bold 0}</m> in exactly its <sq>1</sq> bits.
      </p>
    </statement>
  </definition>
  <example>
    <statement>
      <p>
        Let <m>{\bold x} = (10101)</m>,
        <m>{\bold y} = (11010)</m>,
        and <m>{\bold z} = (00011)</m> be all of the codewords in some code <m>C</m>.
        Then we have the following Hamming distances:
        <md>
          <mrow>d({\bold x},{\bold y}) \amp  = \amp  4,</mrow>
          <mrow>d({\bold x},{\bold z}) \amp  = \amp  3,</mrow>
          <mrow>d({\bold y},{\bold z}) \amp  = \amp  3</mrow>
        </md>.
      </p>
      <p>
        The minimum distance for this code is 3.
        We also have the following weights:
        <md>
          <mrow>w({\bold x}) \amp  = \amp  3,</mrow>
          <mrow>w({\bold y}) \amp  = \amp  3,</mrow>
          <mrow>w({\bold z}) \amp  = \amp  2</mrow>
        </md>.
      </p>
    </statement>
  </example>
  <exercise>
    <statement>
      <p>
        Compute the Hamming distances
            <idx><h>Hamming distance</h></idx>
        between the following pairs of <m>n</m>-tuples.
      </p>
      <sidebyside>
        <ul>
          <li>
            <title>\textbf{(a)}</title>
            <p>
              <m>(011010), (011100)</m>
            </p>
          </li>
          <li>
            <title>\textbf{(c)}</title>
            <p>
              <m>(00110), (01111)</m>
            </p>
          </li>
        </ul>
        <ul>
          <li>
            <title>\textbf{(b)}</title>
            <p>
              <m>(11110101), (01010100)</m>
            </p>
          </li>
          <li>
            <title>\textbf{(d)}</title>
            <p>
              <m>(1001), (0111)</m>
            </p>
          </li>
        </ul>
      </sidebyside>
    </statement>
  </exercise>
  <exercise>
    <statement>
      <p>
        Compute the weights of the following <m>n</m>-tuples.
      </p>
      <sidebyside>
        <ul>
          <li>
            <title>\textbf{(a)}</title>
            <p>
              <m>(011010)</m>
            </p>
          </li>
          <li>
            <title>\textbf{(c)}</title>
            <p>
              <m>(01111)</m>
            </p>
          </li>
        </ul>
        <ul>
          <li>
            <title>\textbf{(b)}</title>
            <p>
              <m>(11110101)</m>
            </p>
          </li>
          <li>
            <title>\textbf{(d)}</title>
            <p>
              <m>(1011)</m>
            </p>
          </li>
        </ul>
      </sidebyside>
    </statement>
  </exercise>
  <exercise xml:id="exercise_ErrorAndCorrectionCode_MinDist">
    <statement>
      <p>
        What is the minimum distance for each of the following block codes?
        <ol>
          <li>
            <p>
              <m>(011010) \; (011100) \; (110111) \; (110000)</m>
            </p>
          </li>
          <li>
            <p>
              <m>(011100) \; (011011) \; (111011) \; (100011)</m> <m>(000000) \; (010101) \; (110100) \; (110011)</m>
            </p>
          </li>
          <li>
            <p>
              <m>(000000) \; (011100) \; (110101) \; (110001)</m>
            </p>
          </li>
          <li>
            <p>
              <m>(0110110) \; (0111100) \; (1110000) \; (1111111)</m> <m>(1001001) \; (1000011) \; (0001111) \; (0000000)</m>
            </p>
          </li>
        </ol>
      </p>
    </statement>
  </exercise>
  <p>
    The weights in a particular block code are usually much easier to compute than the Hamming distances between all codewords in the code.
    As we shall see later,
    if a code is set up carefully then we can use this fact to our advantage.
  </p>
  <p>
    In order to prove statements about Hamming distance and weight,
    it is useful to have a concrete formula for the distance between two codewords.
    Such a formula is given in the following proposition.
  </p>
  <proposition xml:id="proposition_ErrorAndCorrectionCode_HammingDistFormula">
    <statement>
      <p>
        Let <m>{\bold x} = (x_1, \ldots,
        x_n)</m> and <m>{\bold y} = (y_1, \ldots,
        y_n)</m> be binary <m>n</m>-tuples.
        Then the Hamming distance <m>d({\bold x},{\bold y})</m> may be computed by the following formula:
        <me>
          d({\bold x},{\bold y}) = (x_1\oplus y_1) + \ldots (x_n\oplus y_n) )
        </me>,
        where
        <q><m>\oplus</m></q>
        denotes addition mod 2 and
        <q>+</q>
        denotes ordinary addition.
        Using summation notation, the formula can also be written
        <me>
          d({\bold x},{\bold y}) = \sum_{j=1}^n x_j\oplus y_j
        </me>.
      </p>
    </statement>
  </proposition>
  <proof>
    <p>
      For each <m>j</m>,
      we have the 4 possibilities for <m>x_j</m> and <m>y_j</m> shown in <xref ref="ErrorAndCorrectionCode_table3">Table</xref>.
      The table shows that <m>x_j\oplus y_j = 0</m> when <m>x_j = y_j</m>,
      and <m>x_j\oplus y_j = 1</m> when <m>x_j \neq y_j</m>.
      So if we sum these terms for all <m>j</m>,
      we obtain the number of bit positions where
      <m>{\bold x}</m> and <m>{\bold y}</m> differ,
      which by definition is <m>d({\bold x},{\bold y})</m>.
    </p>
  </proof>
  <table xml:id="ErrorAndCorrectionCode_table3">
    <title>Bit sums (mod 2)</title>
    <tabular>
      <row bottom="minor">
        <cell></cell>
        <cell></cell>
        <cell></cell>
      </row>
      <row>
        <cell><m>x_j</m></cell>
        <cell><m>y_j</m></cell>
        <cell><m>x_j \oplus y_j</m></cell>
      </row>
      <row>
        <cell>[0.5ex]
          \hline
          0</cell>
        <cell>0</cell>
        <cell>0</cell>
      </row>
      <row>
        <cell>0</cell>
        <cell>1</cell>
        <cell>1</cell>
      </row>
      <row>
        <cell>1</cell>
        <cell>0</cell>
        <cell>1</cell>
      </row>
      <row>
        <cell>1</cell>
        <cell>1</cell>
        <cell>0</cell>
      </row>
      <row bottom="minor">
        <cell></cell>
        <cell></cell>
        <cell></cell>
      </row>
    </tabular>
  </table>
  <p>
    We have been referring to <m>d( {\bold x}, {\bold y})</m> as
    <q>Hamming distance</q>. To justify this terminology,
    we will prove that the function
    <m>d(\ldots)</m> does indeed possess the properties that we usually associate with a notion of
    <q>distance</q>:
  </p>
  <proposition xml:id="proposition_ErrorAndCorrectionCode_Metric">
    <statement>
      <p>
        Let <m>{\bold x}</m>, <m>{\bold y}</m>,
        and <m>{\bold z}</m> be binary <m>n</m>-tuples.
        Then
        <ol type="a">
          <li>
            <p>
              <m>d( {\bold x}, {\bold y}) \geq 0</m>,
              and <m>d( {\bold x}, {\bold y}) = 0</m> exactly when <m>{\bold x} = {\bold y}</m>;
            </p>
          </li>
          <li>
            <p>
              <m>d( {\bold x}, {\bold y})= d( {\bold y}, {\bold x})</m>;
            </p>
          </li>
          <li>
            <p>
              <m>d( {\bold x}, {\bold y}) \leq d( {\bold x}, {\bold z}) + d( {\bold z}, {\bold y})</m>.
            </p>
          </li>
        </ol>
      </p>
    </statement>
  </proposition>
  <p>
    In higher mathematics,
    any function that satisfies the properties listed in <xref ref="proposition_ErrorAndCorrectionCode_Metric">Proposition</xref>
    is called a <term>metric</term>.
        <idx><h>Metric</h><h>definition</h></idx>
  </p>
  <exercise>
    <statement>
      <p>
        Using the formula in <xref ref="proposition_ErrorAndCorrectionCode_HammingDistFormula">Proposition</xref>,
        prove the statements in <xref ref="proposition_ErrorAndCorrectionCode_Metric">Proposition</xref>.
      </p>
    </statement>
  </exercise>
  <p>
    In order to see how distance relates to error correction,
    consider the case where <m>{\bold x} = (1101)</m> and
    <m>{\bold y} = (1100)</m> are codewords in some code.
    If we transmit (1101) and an error occurs in the rightmost bit,
    then (1100) will be received.
    Since (1100) is a codeword,
    the decoder will decode (1100) as the transmitted message.
    This code is clearly not very appropriate for error detection.
    The problem is that <m>d({\bold x}, {\bold y}) = 1</m>,
    so a single-bit error can change one codeword into a different codeword.
  </p>
  <p>
    On the other hand,
    given the two codewords <m>{\bold x} = (1100)</m> and
    <m>{\bold y} = (1010)</m> then <m>d({\bold x}, {\bold y}) = 2</m>.
    If <m>{\bold x}</m> is transmitted and a single error occurs,
    then no matter which bit is in error it's still impossible for <m>{\bold y}</m> to be received.
    If for example the third bit is mistransmitted and received word is <m>(1110)</m>,
    then we can tell something is wrong <mdash/> that is,
    we can detect that an error has taken place.
    In general, single-bit errors are detectable in any code where the distance between any two codewords is bigger than 1.
  </p>
  <example>
    <statement>
      <p>
        Consider the <m>(4,3)</m> code in which the first three bits carry information and the fourth is an even parity check bit.
        (Note that now we're putting the parity bit on the <em>right</em>
        instead of on the <em>left</em>
        as we did in <xref ref="example_ErrorAndCorrectionCode_evenParity">Example</xref>.
        This will turn out to be more useful in the development of the general theory.)
        <xref ref="ErrorAndCorrectionCode_table1">Table</xref>
        gives the distances between all codewords in this code.
        We can see that the minimum distance here is 2;
        hence, the code is suitable as a single error-detecting code.
      </p>
      <table xml:id="ErrorAndCorrectionCode_table1">
        <title>Distances between 4-bit codewords</title>
        <tabular>
          <row bottom="minor">
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
          </row>
          <row>
            <cell></cell>
            <cell>0000</cell>
            <cell>0011</cell>
            <cell>0101</cell>
            <cell>0110</cell>
            <cell>1001</cell>
            <cell>1010</cell>
            <cell>1100</cell>
            <cell>1111</cell>
          </row>
          <row bottom="minor">
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
          </row>
          <row>
            <cell>0000</cell>
            <cell>0</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>4</cell>
          </row>
          <row>
            <cell>0011</cell>
            <cell>2</cell>
            <cell>0</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>4</cell>
            <cell>2</cell>
          </row>
          <row>
            <cell>0101</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>0</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>4</cell>
            <cell>2</cell>
            <cell>2</cell>
          </row>
          <row>
            <cell>0110</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>0</cell>
            <cell>4</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
          </row>
          <row>
            <cell>1001</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>4</cell>
            <cell>0</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
          </row>
          <row>
            <cell>1010</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>4</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>0</cell>
            <cell>2</cell>
            <cell>2</cell>
          </row>
          <row>
            <cell>1100</cell>
            <cell>2</cell>
            <cell>4</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>0</cell>
            <cell>2</cell>
          </row>
          <row>
            <cell>1111</cell>
            <cell>4</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>2</cell>
            <cell>0</cell>
          </row>
          <row bottom="minor">
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell></cell>
          </row>
        </tabular>
      </table>
    </statement>
  </example>
  <p>
    Let's generalize based on this example.
    Given codewords <m>{\bold x}</m> and <m>{\bold y}</m>:
    <ul>
      <li>
        <p>
          If <m>d({\bold x}, {\bold y}) = 1</m> and an error occurs where
          <m>{\bold x}</m> and <m>{\bold y}</m> differ,
          then <m>{\bold x}</m> is changed to <m>{\bold y}</m>.
          The received codeword is <m>{\bold y}</m> and no error message is given.
        </p>
      </li>
      <li>
        <p>
          If <m>d({\bold x}, {\bold y}) = 2</m>,
          then a single error can't change <m>{\bold x}</m> to <m>{\bold y}</m>.
          Therefore, if <m>d_{\min} = 2</m>,
          we have the ability to detect single errors.
          However, suppose that <m>d({\bold x}, {\bold y}) = 2</m>,
          <m>{\bold y}</m> is sent,
          and a noncodeword <m>{\bold z}</m> is received such that
          <me>
            d({\bold x}, {\bold z}) = d({\bold y}, {\bold z}) = 1
          </me>.
          Then the decoder can't decide between
          <m>{\bold x}</m> and <m>{\bold y}</m>.
          Even though we are aware that an error has occurred,
          we do not know what the error is.
        </p>
      </li>
      <li>
        <p>
          If <m>d_{\min} \geq 3</m>,
          then using the same reasoning it folows that we can detect errors of up to two bits.
          Furthermore,
          the maximum-likelihood decoding scheme <idx><h>Maximum-likelihood decoding</h></idx>
          <em>corrects</em> all single errors.
          Starting with a codeword <m>{\bold x}</m>,
          an error in the transmission of a single bit gives
          <m>{\bold y}</m> with <m>d({\bold x}, {\bold y}) = 1</m>,
          but <m>d({\bold z}, {\bold y}) \geq 2</m> for any other codeword <m>{\bold z} \neq {\bold x}</m>.
          Hence the correct codeword is the closest,
          and will be selected by the decoding scheme.
        </p>
      </li>
    </ul>
  </p>
  <p>
    This line of reasoning leads us to the following general proposition.
  </p>
  <proposition>
    <statement>
      <p>
        Let <m>C</m> be a code with <m>d_{\min} = 2n + 1</m>.
        Then <m>C</m> can correct any <m>n</m> or fewer errors.
        Furthermore,
        any <m>2n</m> or fewer errors can be detected in<nbsp/><m>C</m>.
      </p>
    </statement>
  </proposition>
  <proof>
    <p>
      Suppose that a codeword <m>{\bold x}</m> is sent and the word
      <m>{\bold y}</m> is received with at most <m>n</m> errors.
      Then <m>d( {\bold x}, {\bold y}) \leq n</m>.
      If <m>{\bold z}</m> is any codeword other than <m>{\bold x}</m>, then
      <me>
        2n+1 \leq d( {\bold x}, {\bold z}) \leq d( {\bold x}, {\bold y}) + d( {\bold y}, {\bold z}) \leq n + d( {\bold y}, {\bold z})
      </me>.
    </p>
    <p>
      Hence, <m>d({\bold y}, {\bold z} ) \geq n+1</m> and
      <m>{\bold y}</m> will be correctly decoded as <m>{\bold x}</m>.
      Now suppose that <m>{\bold x}</m> is transmitted and
      <m>{\bold y}</m> is received and that at least one error has occurred,
      but not more than <m>2n</m> errors.
      Then <m>1 \leq d( {\bold x}, {\bold y} ) \leq 2n</m>.
      Since the minimum distance between codewords is <m>2n +1</m>,
      <m>{\bold y}</m> can't be a codeword.
      Consequently,
      the code can detect between 1 and <m>2n</m> errors.
    </p>
  </proof>
  <example>
    <statement>
      <p>
        In <xref ref="ErrorAndCorrectionCode_table2">Table</xref>,
        the codewords <m>{\bold c}_1 = (00000)</m>,
        <m>{\bold c}_2 = (00111)</m>,
        <m>{\bold c}_3 = (11100)</m>,
        and <m>{\bold c}_4 = (11011)</m> determine a single error-correcting code.
      </p>
    </statement>
  </example>
  <table xml:id="ErrorAndCorrectionCode_table2">
    <title>Hamming distances for an error-correcting code</title>
    <tabular>
      <row bottom="minor">
        <cell></cell>
        <cell></cell>
        <cell></cell>
        <cell></cell>
        <cell></cell>
      </row>
      <row>
        <cell></cell>
        <cell>00000</cell>
        <cell>00111</cell>
        <cell>11100</cell>
        <cell>11011</cell>
      </row>
      <row bottom="minor">
        <cell></cell>
        <cell></cell>
        <cell></cell>
        <cell></cell>
        <cell></cell>
      </row>
      <row>
        <cell>00000</cell>
        <cell>0</cell>
        <cell>3</cell>
        <cell>3</cell>
        <cell>4</cell>
      </row>
      <row>
        <cell>00111</cell>
        <cell>3</cell>
        <cell>0</cell>
        <cell>4</cell>
        <cell>3</cell>
      </row>
      <row>
        <cell>11100</cell>
        <cell>3</cell>
        <cell>4</cell>
        <cell>0</cell>
        <cell>3</cell>
      </row>
      <row>
        <cell>11011</cell>
        <cell>4</cell>
        <cell>3</cell>
        <cell>3</cell>
        <cell>0</cell>
      </row>
      <row bottom="minor">
        <cell></cell>
        <cell></cell>
        <cell></cell>
        <cell></cell>
        <cell></cell>
      </row>
    </tabular>
  </table>
  <exercise xml:id="exercise_ErrorAndCorrectionCode_MinDist2">
    <statement>
      <p>
        What are the error detection and correction capabilities for the codes given in <xref ref="exercise_ErrorAndCorrectionCode_MinDist">Exercise</xref>?
      </p>
    </statement>
  </exercise>
  <exercise>
    <statement>
      <p>
        Suppose that a block code <m>C</m> has a minimum weight of 7.
        What are the error-detection and error-correction capabilities of <m>C</m>?
      </p>
    </statement>
  </exercise>
  <exercise>
    <statement>
      <p>
        Construct a <m>(5,2)</m>-block code.
        Discuss the error-detection and error-correction capabilities of your code.
      </p>
    </statement>
  </exercise>
</section>